In this facial emotion recognition project, the dataset comprises 744 images, each representing one of five distinct emotion classes: sad, happy, anger, surprise, and disgust. To facilitate processing, these emotion classes were numerically encoded, ranging from 0 to 4. The dataset was thoughtfully curated to ensure a diverse and balanced representation of each emotion category. Each image captures specific facial expressions corresponding to these emotions. Through meticulous pre-processing, including resizing and normalization, the images were prepared for uniformity in format and pixel values. This structured and labelled dataset acted as the foundation for training and assessing models based on deep learning techniques.  Leveraging MobileNet, a powerful deep learning architecture, the project achieved exceptional accuracy, with MobileNet demonstrating outstanding performance.
The system employs a user interface where users can upload images to display emotions on-screen. Additionally, it features a webcam option allowing users to convey facial expressions in real-time, enabling immediate identification and display of emotions. Upon ending the video session, users are presented with a plotted analysis of the emotions detected throughout the video.
